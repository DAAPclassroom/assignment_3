{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3\n",
    "\n",
    "Due: **10:00 14. Mai 2024**\n",
    "\n",
    "Discussion: **12:00 28. Mai 2024**\n",
    "\n",
    "**Online submission** at via github classroom  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Supernova rate per century - SN1987A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we discussed the example of how to estimate the expected rate of supernovae per century, based on past occurances of\n",
    "supernovae. Using a Bayesian approach we found that the posterior probabilty distribution of supernovae per cuntury (visible by naked eye)\n",
    "can be described for n supernovae in m centuries as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{P}(\\rho\\mathrm{|data}) = \\frac{\\rho^n(1-\\rho)^{m-n}}{B(n+1, m-n+1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the denominator is used to normalize the distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\int_0^1\\mathcal{P}(\\rho\\mathrm{|data}) d\\rho = \\int_0^1 \\binom{m}{n} \\rho^n (1-\\rho)^{m-n} d\\rho =$$\n",
    "\n",
    "$$ \\binom{m}{n} \\frac{\\Gamma(m-n+1)\\Gamma(n+1)}{\\Gamma(m+2)} = \\binom{m}{n} B(n+1, m-n+1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Write a computer program, to compute $\\mathcal{P}(ρ |\\mathrm{data})$ for any n supernovae in `m` centuries. **10 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Plot the distribution $\\mathcal{P}(ρ |\\mathrm{data})$ for 4 supernovae in 10 centuries and for 5 supernovae in 10 centuries in the same Figure. **5 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Assume, that the true distribution $\\mathcal{P}(ρ |\\mathrm{data})$ would be $\\mathcal{P}(ρ |\\mathrm{data})= \\frac{\\rho^8(1-\\rho)^{10-8}}{B(8+1, 10-8+1)}$ i.e. 8 supernovae in 10 centuries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **i.** Plot the distribution now. **5 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **ii.** Compute the probability, given this distribution, to observe 5 supernovae or less in 10 centuries. **10 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Samples & Sampling Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a numerical simulation code that reproduces the behaviour of the following simulation. (Also shown in the lecture.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw N samples of size n from a population with $\\mu=5$ and $\\sigma=1$. Compute the confidence intervals (CI) of each sample distribution and the sampling distribution and visualize it in a similar manner. Test your simulation against your theoretical expectations. Make sure to test your result and to confirm that the result is as expected. (i.e. About 5 % of the samples not overlapping with the confidence interval, or 5% of all simulations with the population mean not part of the confidence interval.) **30 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parametric tests: mean\n",
    "A very common question arises when we have two sets of data (or one set of data and a model) and we ask if they differ in location. To contrast the classical and Bayesian methods for hypothesis testing, we look at the simple case of comparison of means. We deal with a Gaussian distribution, because its analytical tractability has resulted in many tests being developed for Gaussian data; and then, of course, there is the central limit theorem.\n",
    "\n",
    "Let us suppose we have $n$ data $X_i$ drawn from a Gaussian of mean $\\mu_x$, and $m$ other data $Y_i$, drawn from a Gaussian of **identical variance** but different mean $\\mu_y$. Call the common variance $\\sigma^2$. The Bayesian method is to calculate the joint posterior distribution:\n",
    "\n",
    "$$ \\mathcal{P}(\\mu_x,\\mu_y,\\sigma)\\propto\\dfrac{1}{\\sigma^{n+m+1}}\\exp\\left(-\\dfrac{\\Sigma_i (x_i-\\mu_x)^2}{2\\sigma^2}\\right)\\exp\\left(-\\dfrac{\\Sigma_i (y_i-\\mu_y)^2}{2\\sigma^2}\\right) $$\n",
    "\n",
    "in which we have used the Jeffreys prior for the variance. Integrating over the 'nuisance' parameter $\\sigma$, we would get the joint probability prob($\\mu_x,\\mu_y$) and could use it to derive, for example, the probability that $\\mu_x$ is bigger than $\\mu_y$. From this we can calculate the probability distribution of ($\\mu_x-\\mu_y$). The result depends on the data via a quantity\n",
    "\n",
    "$$ t^\\prime = \\dfrac{(\\mu_x-\\mu_y)-(\\bar{X}-\\bar{Y})}{s\\sqrt{\\frac{1}{m}+\\frac{1}{n}}}, \\qquad \\textrm{where} \\qquad s^2 = \\dfrac{nS_x+mS_y}{\\nu} $$\n",
    "\n",
    "with the usual mean squares $S_x = \\Sigma (X_i-\\bar{X})^2 / n$, similarly for $S_y$, and $\\nu=n+m-2$. $s$ is called pooled standard deviation. The probability for $t^\\prime$ is\n",
    "\n",
    "$$ \\mathcal{P}(t^\\prime) = \\dfrac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\pi\\nu}\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left(1+\\dfrac{t^{\\prime 2}}{\\nu}\\right)^{-\\frac{1}{2}(\\nu+1)} $$\n",
    "\n",
    "We regard the data as fixed and $(\\mu_x-\\mu_y)$ as the variable, simply computing the probability of any particular difference in the means. We might alternatively work out the range of differences whichare, say, 90 percent probable, or we might carry the distribution of $(\\mu_x-\\mu_y)$ on into a later probabilistic calculation. If we instead follow the classical line of reasoning, we do not treat the $\\mu$'s as random variables. Instead we guess that the difference in the averages $X-Y$ will be the statistic we need; and we calculate its distribution on the null hypothesis that $\\mu_x=\\mu_y$. We find that\n",
    "\n",
    "$$ t=\\dfrac{\\bar{X}-\\bar{Y}}{s\\sqrt{\\frac{1}{m}+\\frac{1}{n}}} $$\n",
    "\n",
    "follows a t-distribution with $(n+m-2)$ degrees of freedom. This is the classical Student's t. This gives the basis of a classical hypothesis test, the t-test for means. Assuming that $(\\mu_x-\\mu_y)=0$ (the null hypothesis), we calculate t. If it (or some greater value) is very unlikely, we think that the null hypothesis is ruled out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** Suppose we have two small sets of data, from Gaussian distributions of equal variance: $(-1.22, -1.17, 0.93, -0.58, -1.14) \\in A$ and $(1.03, -1.59, -0.41, 0.71, 2.10) \\in B$. Compute the respective mean values and the pooled standard deviation $s$ **5 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Compute the t statistic. Perform a two tailed test. What is the chance that these data would arise if the means were the same. What is the chance if we did a one-tailed test? **10 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Calculate the distribution of $(\\mu_x-\\mu_y)$ from a Bayesian point of view and plot the resulting prob($\\mu_x-\\mu_y$) as a function of $(\\mu_x-\\mu_y)$. What is the chance that $\\mu_x$ is not smaller than $\\mu_y$? **10 Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** By analogous calculations we arrive at the F test for variances. Again Gaussian distributions are assumed. The null hypothesis is $\\sigma_x=\\sigma_y$, the data are $X_i (i=1,\\ldots,n)$ and $Y_i (i=1,\\ldots,m)$ and the test statistic is,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\cal F} = \\dfrac{\\Sigma_i\\left(X_i-\\bar{X}\\right)^2/(n-1)}{\\Sigma_i\\left(Y_i-\\bar{Y}\\right)^2/(m-1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This follows the F ratio distribution with $(n-1)$ and $(m-1)$ degrees of freedom. The testing is the as for the Student's t. Perform a test whether the variances of the two data sets are the same. **15 Points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "date": "",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "title": ""
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
